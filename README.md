<h1>Data Modeling with Postgres for a startup called Sparkify</h1>

<h2>1. purpose of this database</h2>

<p>The purpose of this database is collectiong songs and user activities on the new music streaming app 
and understanding what songs users are listeing to optimize their user analysis.</p>

<h2>2. database schema design and ETL pipeline</h2>
This database is star schema that simplifies business reporting and implements fast aggregation for this analysis.

<h4>Fact Table</h4>
<ol>
      <li><strong>songplays</strong> - records in log data associated with song plays i.e. records with page NextSong
            <ul>
                  <li>songplay_id  --> PRIMARY KEY </li>
                  <li>start_time </li>
                  <li>user_id </li>
                  <li>level</li>
                  <li>user_id </li>
                  <li>song_id</li>
                  <li>artist_id</li>
                  <li>session_id</li>
                  <li>location</li>
                  <li>user_agent</li>
            </ul>
      </li>
</ol>

<h4>Dimension Tables</h4>
<ol>
      <li><strong>users</strong> - users in the app
            <ul>
                  <li>user_id  --> PRIMARY KEY</li>
                  <li>first_name</li>
                  <li>last_name</li>
                  <li>gender</li>
                  <li>level</li>
            </ul>
      </li>
      <li><strong>songs</strong> - songs in music database
            <ul>
                  <li>song_id  --> PRIMARY KEY</li>
                  <li>title</li>
                  <li>artist_id</li>
                  <li>year</li>
                  <li>duration</li>
            </ul>
      </li>
      <li><strong>artists</strong> - artists in music database
            <ul>
                  <li>artist_id  --> PRIMARY KEY</li>
                  <li>name</li>
                  <li>location</li>
                  <li>latitude</li>
                  <li>longitude</li>
            </ul>
      </li>
      <li><strong>time</strong> - timestamps of records in songplays broken down into specific units
            <ul>
                  <li>start_time  --> PRIMARY KEY</li>
                  <li>hour</li>
                  <li>day</li>
                  <li>week</li>
                  <li>month</li>
                  <li>year</li>
                  <li>weekday</li>
            </ul>
      </li>
</ol>

<h2>3. Explanation of the files</h2>
<p><strong>data/song_data</strong> - subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. </p>

<p><strong>data/log_data</strong> - consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. 
These simulate activity logs from a music streaming app based on specified configurations.</p>

<p><strong>create_tables.py</strong> - creates all 5 tables using SQL queries in sql.queries.py</p>

<p><strong>etl.py</strong> - reads and processes files from song_data and log_data and loads them into tables. </p>

<p><strong>sql.queries.py</strong> - contains all sql queries.</p>

<h2>4. How to run</h2>
<p>Run <strong><em>create_tables.py</em></strong> and then <strong><em>etl.py</em></strong></p>
